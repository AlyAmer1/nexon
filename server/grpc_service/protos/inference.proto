// File: server/grpc_service/protos/inference.proto
// Version: 2.0 (Final, Thesis-Parity & Production-Ready) | Author: Aly Amer | Date: 08.09.2025
// Implements a scientifically valid request contract and a usable response contract.
syntax = "proto3";

package nexon.grpc.inference.v1;

service InferenceService {
  // Unary RPC that mirrors the functionality of the POST /infer/{model_name} REST endpoint.
  rpc Predict(PredictRequest) returns (PredictReply);
}

// --- Request/Reply Messages ---

message PredictRequest {
  // Matches the 'model_name' path parameter in the REST API.
  string model_name = 1;

  // A single input tensor, using the request-specific tensor message.
  RequestTensor input = 2;
}

message PredictReply {
  // A list of output tensors, using the response-specific tensor message.
  repeated ResponseTensor outputs = 1;
}

// --- Tensor Definitions ---

// Tensor for requests: The client does NOT provide the data_type.
// This ensures the gRPC server's workload perfectly mirrors the REST server's workload,
// as the server must derive the data type from the ONNX model's metadata.
message RequestTensor {
  // The shape of the tensor (e.g., [1, 28, 28]).
  repeated int64 dims = 1;
  // The optional name of the tensor.
  string name = 2;
  // The raw tensor content in row-major (C-order), little-endian format.
  bytes tensor_content = 3;
}

// Tensor for responses: The server MUST provide the data_type.
// This is essential for the client to correctly decode the raw tensor_content bytes.
message ResponseTensor {
  repeated int64 dims = 1;
  string name = 2;
  bytes tensor_content = 3;
  DataType data_type = 4; // The crucial difference for usability.
}

// --- Enum Definition ---

enum DataType {
  DT_UNSPECIFIED = 0;
  DT_FLOAT32 = 1;
  DT_FLOAT64 = 2;
  DT_INT32   = 3;
  DT_INT64   = 4;
  DT_BOOL    = 5;
  DT_STRING  = 6;
}